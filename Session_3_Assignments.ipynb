{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEAQyibDJlXTLPn65xqZJX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaKumari500092077/Machine-Learning-Lab/blob/main/Session_3_Assignments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment - 2**"
      ],
      "metadata": {
        "id": "h76lN0-6XUGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Objective** - Classify emails as spam or not spam using the [Spambase](https://archive.ics.uci.edu/static/public/94/data.csv) dataset, which contains the frequency of occurrence of 57 entities (words and characters) (in %) from 4601 spam and non-spam emails and corresponding class labels.  "
      ],
      "metadata": {
        "id": "WPElE_3xXV8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spam Classification with Logistic Regression\n",
        "\n",
        "<font color='blue'>Task 1: Load the Spambase Dataset</font> [Marks - 1]\n",
        "\n",
        "- Load the Spambase dataset using Pandas.\n",
        "- Display the first few rows to understand the structure of the data.\n",
        "\n",
        "<font color='blue'>Task 2: Check for Duplicate Entries and Missing Values</font> [Marks - 1]\n",
        "\n",
        "- Check if there are duplicate entries in the dataset.\n",
        "- Remove any duplicate entries.\n",
        "- Check for missing values in the dataset.\n",
        "- Remove entries with missing feature values.\n",
        "\n",
        "<font color='blue'>Task 3: Preprocess the Dataset</font> [Marks - 1]\n",
        "\n",
        "- Preprocess the dataset as required:\n",
        "- Perform feature scaling or standardization on the features.\n",
        "\n",
        "<font color='blue'>Task 4: Check Dataset Balance</font> [Marks - 1]\n",
        "\n",
        "- Determine if the dataset is balanced or imbalanced by analyzing the distribution of the target variable.\n",
        "\n",
        "<font color='blue'>Task 5: Split the Data</font> [Marks - 1]\n",
        "\n",
        "- Split the data into training, validation, and test sets with the following proportions:\n",
        "  - Training set: 70%\n",
        "  - Validation set: 15%\n",
        "  - Test set: 15%\n"
      ],
      "metadata": {
        "id": "seZaOWBfXcMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Task 6: Implement Logistic Regression from Scratch</font> [Marks - 8]\n",
        "\n",
        "- Implement a logistic regression model from scratch using:\n",
        "  - Cross-entropy loss as the cost function.\n",
        "  - Gradient descent as the learning algorithm.\n",
        "  - L1 regularization in the cost function.\n",
        "- Train the logistic regression model using gradient descent.\n",
        "- Choose appropriate values for the learning rate and regularization parameter through cross-validation.\n",
        "\n",
        "<font color='blue'>Task 7: Evaluate Model Performance</font> [Marks - 2]\n",
        "\n",
        "- Evaluate the performance of your logistic regression model on the test set using:\n",
        "  - Confusion matrix.\n",
        "  - Precision.\n",
        "  - Recall.\n",
        "  - Area under the Precision-Recall Curve (AUC-PR).\n"
      ],
      "metadata": {
        "id": "0CggugT9XhQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Task 8: Compare with Scikit-Learn</font> [Marks - 5]\n",
        "\n",
        "- Fit a logistic regression model using scikit-learn.\n",
        "- Compare the performance of your implementation with the scikit-learn model by evaluating:\n",
        "  - Confusion matrix.\n",
        "  - Precision.\n",
        "  - Recall.\n",
        "  - Area under the Precision-Recall Curve (AUC-PR).\n",
        "- Compare the AUC-PR values between your implementation and scikit-learn's implementation."
      ],
      "metadata": {
        "id": "DXgROlKdXo10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHP0uYrKXzOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNR-z11WX8zU",
        "outputId": "2729bd35-e0c7-4dfc-d0e3-6307e09acd2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.1.4)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.7.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# # fetch dataset\n",
        "# spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "# # data (as pandas dataframes)\n",
        "# X = spambase.data.features\n",
        "# y = spambase.data.targets\n",
        "\n",
        "# # metadata\n",
        "# print(spambase.metadata)\n",
        "\n",
        "# # variable information\n",
        "# print(spambase.variables)"
      ],
      "metadata": {
        "id": "OTfyr4kWYDZg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/static/public/94/data.csv\")"
      ],
      "metadata": {
        "id": "rsWb6YLiYZMx"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}