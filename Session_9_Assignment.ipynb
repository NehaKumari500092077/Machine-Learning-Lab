{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWLq1mYoOhy+GvgpvxErDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaKumari500092077/Machine-Learning-Lab/blob/main/Session_9_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 9**: Random Forest Regression\n",
        "\n",
        "Objective: This assignment provides a hands-on understanding of the Random Forest Regression algorithm. You will implement the algorithm from scratch and compare its performance with the scikit-learn implementation. You will also tune hyperparameters using cross-validation.\n",
        "\n",
        "Dataset:  Diabetes dataset (https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes)\n",
        "\n",
        "Tasks:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZOAUAGxS9cO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Preparation: [1 Marks]\n",
        "*   Load the diabetes dataset using sklearn.datasets.load_diabetes.\n",
        "*   Split the dataset into training and test sets with a 80%-20% ratio."
      ],
      "metadata": {
        "id": "9b8gX_6s9ppz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "diabetes_data = load_diabetes()\n",
        "X = diabetes_data.data\n",
        "Y = diabetes_data.target\n",
        "dataset = pd.DataFrame(data=np.c_[X, Y], columns=diabetes_data.feature_names + ['target'])\n",
        "print(dataset.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNx5zyXw_Mme",
        "outputId": "8578d25c-3560-427e-aed0-c222a311bbdd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 442 entries, 0 to 441\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   age     442 non-null    float64\n",
            " 1   sex     442 non-null    float64\n",
            " 2   bmi     442 non-null    float64\n",
            " 3   bp      442 non-null    float64\n",
            " 4   s1      442 non-null    float64\n",
            " 5   s2      442 non-null    float64\n",
            " 6   s3      442 non-null    float64\n",
            " 7   s4      442 non-null    float64\n",
            " 8   s5      442 non-null    float64\n",
            " 9   s6      442 non-null    float64\n",
            " 10  target  442 non-null    float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 38.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfYLHzkyEDs7",
        "outputId": "cdd104e1-f1c1-47fb-c160-269c31b86e9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age       sex       bmi        bp  ...        s3        s4        s5        s6\n",
            "0  0.038076  0.050680  0.061696  0.021872  ... -0.043401 -0.002592  0.019907 -0.017646\n",
            "1 -0.001882 -0.044642 -0.051474 -0.026328  ...  0.074412 -0.039493 -0.068332 -0.092204\n",
            "2  0.085299  0.050680  0.044451 -0.005670  ... -0.032356 -0.002592  0.002861 -0.025930\n",
            "3 -0.089063 -0.044642 -0.011595 -0.036656  ... -0.036038  0.034309  0.022688 -0.009362\n",
            "4  0.005383 -0.044642 -0.036385  0.021872  ...  0.008142 -0.002592 -0.031988 -0.046641\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicates\n",
        "duplicates_value = dataset.duplicated().sum()\n",
        "print(f'No. of Duplicates: {duplicates_value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WteBqL07A_Ac",
        "outputId": "51441508-81f1-4b06-8e51-8bb9174dc947"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of Duplicates: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "missing_value = dataset.isnull().sum()\n",
        "print(f'Total Number of Missing Values: {missing_value.sum()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnjHWv8NBYTI",
        "outputId": "48c24974-4bfa-419c-d786-c086cd40a636"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Missing Values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "dataset = sc.fit_transform(dataset)"
      ],
      "metadata": {
        "id": "uuesfGIeCFU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into traing and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataset.drop('target', axis=1)\n",
        "Y = dataset['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, dataset.target, test_size=0.20, random_state=42)\n",
        "\n",
        "print(x.columns)\n",
        "print(y.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "fseYdtUWCIbf",
        "outputId": "0979471a-036a-41c1-cbff-54afced306e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-abe602b1aca1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. From-Scratch Implementation: [7 Marks]\n",
        "* Implement the Random Forest Regression algorithm from scratch in Python."
      ],
      "metadata": {
        "id": "cfJrY9Ms9wmr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEdOUrWg-MUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Hyperparameter Tuning (From-Scratch Implementation): [5 Marks]\n",
        "* Use GridSearchCV from scikit-learn to find the optimal number of trees for your from-scratch implementation.\n",
        "* Evaluate the model with the best number of trees on the test set and report the Mean Squared Error (MSE) and the OOB error.\n"
      ],
      "metadata": {
        "id": "cu2DcSgd91J7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WT135u0S-NSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Scikit-learn Implementation: [5 Marks]\n",
        "* Use RandomForestRegressor from scikit-learn to train a model on the diabetes dataset.\n",
        "* Using cross-validation find the optimal number of trees for the scikit-learn implementation.\n",
        "* Evaluate the model with the best number of trees on the test set and report the MSE and OOB.\n"
      ],
      "metadata": {
        "id": "3J06RHYw95bT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcb6viSz-ORG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. Comparison and Visualization: [2 Marks]\n",
        "* Compare the performance (MSE) of your from-scratch implementation with the scikit-learn implementation.\n",
        "* Create scatter plots to visualize:\n",
        "  * Predicted values vs. true values for your from-scratch implementation.\n",
        "  * Predicted values vs. true values for the scikit-learn implementation.\n",
        "* Display these plots side-by-side for easy comparison."
      ],
      "metadata": {
        "id": "Ekpj-z0L-FH1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdk62RbZ-PEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}